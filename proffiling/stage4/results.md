# Проифилирование нагрузки 4-го этапа
Нагрузочное тестирование с помощью wrk2 (код скрипта использовался из stage 1).
На данном этапе стреляем в 64 соединения и 4 потока.

## Анализ PUT-запросов и сравнение с реализацией прошлого этапа
#### Результаты wrk
Использовалась следующая команда терминала:
wrk -t4 -c64 -d20s -s proffiling/lua-scripts/put.lua -R50000 --latency http://127.0.0.1:8080

##### Рандеву хеширование
Результаты нагрузки:

##### По модулю
Результаты нагрузки:


При рассмотрении двух вариантов мы видим что средняя задержка практически одинакова, но зато
максимальная задержка, которая была зафиксирована в диапазоне от 99.900 до 99.999 вдове уменьшилась,
с 40 мс до 20 мс.

#### Результаты профилирования для cpu с помощью Async-profiler

![async-profiler put cpu](flamegraphs/async_put_cpu.svg)

Наша ассинхронная реализация в левом углу имеет 8 стеков NIOSelector-ов, котороые в предидущей
реализации были внизу каждого стека, каждый из воркеров при этом заниммает по 1.8% нашего процессора,
а у основания стека каждого потока мы имеем наши пронумерованные ворекры. При этом без ассинхронномтси
воркеры занимали у нас по 12% процессора на каждый поток, а воркеры 10%, при этом мы понимаем что,
раз селекторы заняты лишь на 2% то мы могли бы при наличии ресурсов и дальше увеличивать количество
соединений и потоков, особого простоя мы бы не достигили.

#### Результаты профилирования Allocation с помощью Async-profiler

![async-profiler put cpu](flamegraphs/async_put_alloc.svg)

По выделению памяти в случае ассинхронной реализации мы также имеем разделение. Память у нас выделяется
под каждый наш селектор 6.47% (на поток) и отдельно ворекры. HttpSession.sendResponse у нас ожидаем
находится в воркере и занимает по 1.79% на поток, а DAO.upsert занимает всего 0.88% на поток.
В случае с не асинхронной реализацией, мы выделиляли 1.2% на ответ и 1.32% на запрос в базу.

При этом в обоих случаях мы тратили достаточно много на выделение памяти под парсинг запроса.
Но в асинхронной реализации граф показывает что мы тратили на это меньше 1.61% вместо 6.4%.
 
#### Результаты профилирования Lock с помощью Async-profiler
 
  Асинхронный:
 ![async-profiler put cpu](flamegraphs/async_put_lock.svg)

В данном случае это самое главное отличие двух реализаций. На прошлом этапе у нас ничего нигде не 
блокировалось, а в асинхронной реализации уже показывает себя ArrayBlockingQueue. Как бы то нибыло,
все потоки одинаковых размеров, а значит мы не имеем доминирующих и голодающих потоков.
 
 
 ## Анализ GET-запросов и сравнение с реализацией прошлого этапа
 #### Результаты wrk
 Использовалась следующая команда терминала:
  wrk -t4 -c64 -d20s -s proffiling/lua-scripts/get.lua -R50000 --latency http://127.0.0.1:8080
 
 ##### Рандеву хеширование
 Результаты нагрузки:
 
 ##### По модулю
 Результаты нагрузки:
 
В случае get, мы имеем примерно одинаковую среднюю задержку, но в случае с асинхронной реализацеией
её максимальные значения увеличились с 18-20 мс до 21-29 для 99.900-100%. Это всё равно не критичная,
задерка, особенно учитывая что для LSM хранилищ put является наиболее важной операцией. 
  
 #### Результаты профилирования для cpu с помощью Async-profiler
   
 Асинхронный:
 ![async-profiler put cpu](flamegraphs/async_get_cpu.svg)

 Аналогично put-запросам, в асинхронной реализации у нас появились отдельные потоки селекторов, в случае
 с get запросом они тратят 3.2% на поток. 3.6% на поток уходит на операцию get (DAOImpl) при асинхронной реализации
 и 7.19% при обычной. На отправку ответа в случае в асинхронной реализации тратится 4.11% на поток, а в
 обычной 3.6% (HttpSession.sendResponse).
 
 #### Результаты профилирования Allocation с помощью Async-profiler
 
  ![async-profiler put cpu](flamegraphs/async_get_alloc.svg)
 
 По выделению памяти в случае ассинхронной реализации мы также имеем разделение. Память у нас выделяется
 под каждый наш селектор 6.4% (на поток) и отдельно ворекры 6.22 (в не асинхронной реализации орба стека
 объединены и занимают 12.3%. HttpSession.sendResponse занимает по 1.76% на поток, 
 а DAO.get занимает 1.66% на поток.
 В случае с не асинхронной реализацией, мы выделиляли 1.7% на ответ и 1.5% на запрос в базу.
 
 При этом в обоих случаях мы тратили достаточно много на выделение памяти под парсинг запроса.
 Но в асинхронной реализации граф показывает что мы тратили на это меньше 1.61% вместо 6.4%.

#### Результаты профилирования Lock с помощью Async-profiler

  ![async-profiler put cpu](flamegraphs/async_get_lock.svg)

### Выводы
