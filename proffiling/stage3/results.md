# Проифилирование нагрузки 3-го этапа
Нагрузочное тестирование с помощью wrk2 (код скрипта использовался из stage 1):
- 4 потока, 16 соединение, 60 секунд, 15000 запросов в секунду

## Подбор уровня оптимальной нагрузки


## Анализ PUT-запросов и сравнение с реализацией прошлого этапа

Использовалась следующая команда терминала:
wrk -t4 -c16 -d60s -s proffiling/lua-scripts/put.lua -R15000 --latency http://127.0.0.1:8080

Был получен следующий результат:
     

Как мы можем видеть, средняя задержка для операции put, составила всего 11 ms при отклонении
в 96%. На 90 процентов запросов система отвечает быстрей чем за 3 милесекунды. Но на промежутке
от 90 до 100% мы имеем существенное увеличение отлика.

#### Результаты профилирования для cpu с помощью Async-profiler

![async-profiler put cpu](flamegraphs/put_cpu.svg)

Анализуря данный граф, мы можем увидеть, что 99.9% cpu занимает SelectorThread.run, который обрабатывает
запросы. По стеку вызово, мы видим что 40.9% занимает работа нативного метода rocksdb - put. Также 
мы видим что справа от put появился маленький столбец _pthread_cond_signal, в нашем случае этот стэк
заканчивается lock-ом, и отвечает за потокобезопасность добавления данных и уходит в POSIX. Порядка
 30% уходит на отправку ответов.  

#### Результаты профилирования Allocation с помощью Async-profiler

![async-profiler put alloc](flamegraphs/put_alloc.svg)

На данном графе можно посмотреть выделение памяти под процессы. SelectorThread.run занимает 100%.
При этом на one/nio/http/HttpSession.sendResponse мы тратим 11% памяти, и 20% на парсинг запроса.
На операцию put (ServiceImpl.put) тратится 32%. Все что указано на верху голубым цветом, по большому счету является safe point-ами jvm, и появились 
в стэке только по причине остановки потоков при семплинорвании именно на этом моменте.
 
#### Результаты профилирования Lock с помощью Async-profiler
 
 ![async-profiler put alloc](flamegraphs/put_lock.svg)

Данный граф отображает блокировки потоков, и как мы можем увидеть отображаеть ему нечего, и это 
определенно хороший знак.
 
 ### Анализ GET-запросов и сравнение с реализацией прошлого этапа
 Использовалась следующая команда терминала:
 wrk -t4 -c16 -d60s -s proffiling/lua-scripts/get.lua -R15000 --latency http://127.0.0.1:8080
 
 Был получен следующий результат:
   
 
 В случае с get запросом мы имеем более радужную картину. Мы имеем среднюю зажерэку в 1.5 
 миллесекунды, при стандартном откланении в 86%. Как мы можем видеть, 90% наших запросов 
 укладываются в 3 мс, а 99% в 5 мс.
 
  #### Результаты профилирования для cpu с помощью Async-profiler
   
 ![async-profiler get cpu](flamegraphs/get_cpu.svg)
 
 Основываясь на результатах мы можем сделать выводы о том что 99% cpu занимает SelectorThread, также  
 35% cpu уходит на операцию get (ServiceImpl) , а на отправку ответов 42%(HttpSession.sendResponse).
 
 #### Результаты профилирования Allocation с помощью Async-profiler
 
 ![async-profiler get alloc](flamegraphs/get_alloc.svg)
 
 Основываясь на результатах мы можем сделать выводы о том что 100% cpu занимает SelectorThread, также  
 32% cpu уходит на операцию get (ServiceImpl) , а на отправку ответов 12% (HttpSession.sendResponse).

#### Результаты профилирования Lock с помощью Async-profiler
 
 ![async-profiler put alloc](flamegraphs/get_lock.svg)

Данный граф отображает блокировки потоков, и как мы можем увидеть отображаеть ему нечего, и это 
определенно хороший знак.
